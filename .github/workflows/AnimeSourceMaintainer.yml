name: AnimeSourceMaintainer (DO NOT TOUCH)

on:
  push:
    paths:
      - 'Directorys/Files/Anime/**'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: write

jobs:
  build-index:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v3
        with:
          # Ensure full history so we can rebase cleanly
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Sync branch with remote
        shell: bash
        run: |
          set -euo pipefail
          BRANCH="${GITHUB_REF_NAME:-$(git rev-parse --abbrev-ref HEAD)}"
          echo "Resetting local branch '$BRANCH' to match origin/$BRANCH"
          git fetch --no-tags --prune origin "$BRANCH"
          git checkout "$BRANCH"
          git reset --hard "origin/$BRANCH"

      - name: Install image processor (sharp)
        run: npm install sharp@0.33

      - name: Generate and push anime sources
        shell: bash
        env:
          COMMIT_MESSAGE: 'chore: update Directorys/AnimeSourceList.json and anime posters'
          COMMIT_USER_NAME: github-actions[bot]
          COMMIT_USER_EMAIL: 41898282+github-actions[bot]@users.noreply.github.com
        run: |
          set -euo pipefail
          BRANCH="${GITHUB_REF_NAME:-$(git rev-parse --abbrev-ref HEAD)}"
          FILE_DIR="Directorys/Files/Anime"
          INDEX_FILE="Directorys/AnimeSourceList.json"
          POSTERS_DIR="Directorys/Posters/Anime"

          if [[ ! -d "$FILE_DIR" ]]; then
            echo "Directory '$FILE_DIR' does not exist; nothing to index."
            exit 0
          fi

          generate_sources() {
            node <<'NODE'
          const fs = require('fs');
          const path = require('path');
          const http = require('http');
          const https = require('https');
          const sharp = require('sharp');

          const HIDDEN_JSON_KEYS = ['hidden', 'Hidden', 'maintainerHidden'];

          function isMaintainerHidden(entry) {
            if (!entry || typeof entry !== 'object') return false;
            return HIDDEN_JSON_KEYS.some((key) => entry[key] === true);
          }

          function coerceSeparatedFlag(value) {
            if (value === true) return true;
            if (value === false) return false;
            if (typeof value === 'number') return value !== 0;
            if (typeof value === 'string') {
              const trimmed = value.trim().toLowerCase();
              if (!trimmed) return false;
              if (['1','true','yes','y','separated','seperate'].includes(trimmed)) return true;
              if (['0','false','no','n'].includes(trimmed)) return false;
            }
            return false;
          }

          function pickNumeric(values) {
            for (const value of values) {
              const num = Number(value);
              if (Number.isFinite(num) && num > 0) return num;
            }
            for (const value of values) {
              const num = Number(value);
              if (Number.isFinite(num) && num === 0) return 0;
            }
            return null;
          }

          function collectEpisodeParts(entry) {
            if (!entry || typeof entry !== 'object') return [];
            const candidates = [
              Array.isArray(entry.sources) ? entry.sources : null,
              Array.isArray(entry.parts) ? entry.parts : null,
              Array.isArray(entry.items) ? entry.items : null,
              Array.isArray(entry.__separatedParts) ? entry.__separatedParts : null
            ];
            for (const candidate of candidates) {
              if (Array.isArray(candidate) && candidate.length) {
                return candidate.filter(part => part && typeof part === 'object');
              }
            }
            return [];
          }

          function deriveEpisodeStats(entry) {
            const parts = collectEpisodeParts(entry);
            const sizeCandidates = [
              entry && entry.fileSizeBytes,
              entry && entry.FileSizeBytes,
              entry && entry.ItemfileSizeBytes,
              entry && entry.itemFileSizeBytes,
              entry && entry.totalFileSizeBytes,
              entry && entry.sizeBytes,
              entry && entry.size
            ];
            let size = pickNumeric(sizeCandidates);
            if ((size === null || size <= 0) && parts.length) {
              let sum = 0;
              for (const part of parts) {
                const partSize = pickNumeric([
                  part && part.fileSizeBytes,
                  part && part.FileSizeBytes,
                  part && part.partfileSizeBytes,
                  part && part.itemFileSizeBytes,
                  part && part.ItemfileSizeBytes,
                  part && part.sizeBytes,
                  part && part.size
                ]);
                if (Number.isFinite(partSize) && partSize > 0) sum += partSize;
              }
              if (sum > 0) size = sum;
            }

            const durationCandidates = [
              entry && entry.durationSeconds,
              entry && entry.DurationSeconds,
              entry && entry.itemDurationSeconds,
              entry && entry.ItemDurationSeconds,
              entry && entry.ItemdurationSeconds,
              entry && entry.totalDurationSeconds,
              entry && entry.runtimeSeconds,
              entry && entry.runtime,
              entry && entry.lengthSeconds,
              entry && entry.lengthInSeconds,
              entry && entry.timeSeconds
            ];
            let duration = pickNumeric(durationCandidates);
            if ((duration === null || duration <= 0) && parts.length) {
              let sum = 0;
              for (const part of parts) {
                const partDuration = pickNumeric([
                  part && part.durationSeconds,
                  part && part.DurationSeconds,
                  part && part.partDurationSeconds,
                  part && part.partDuration,
                  part && part.lengthSeconds,
                  part && part.lengthInSeconds,
                  part && part.timeSeconds
                ]);
                if (Number.isFinite(partDuration) && partDuration > 0) sum += partDuration;
              }
              if (sum > 0) duration = sum;
            }

            return {
              size: Number.isFinite(size) && size > 0 ? size : 0,
              duration: Number.isFinite(duration) && duration > 0 ? duration : 0,
              partCount: parts.length
            };
          }

          function getCategoryEntries(category) {
            if (!category || typeof category !== 'object') return [];
            if (Array.isArray(category.episodes)) return category.episodes;
            if (Array.isArray(category.items)) return category.items;
            return [];
          }

          const FILE_DIR = 'Directorys/Files/Anime';
          const INDEX_FILE = 'Directorys/AnimeSourceList.json';
          const POSTERS_DIR = 'Directorys/Posters/Anime';
          if (!fs.existsSync(POSTERS_DIR)) fs.mkdirSync(POSTERS_DIR, { recursive: true });

          function safePosterName(title, fallback) {
            const base = String(title || fallback || 'poster')
              .trim()
              .replace(/[\\/:*?"<>|]+/g, ' ')
              .replace(/\s+/g, ' ')
              .replace(/\./g, '_')
              .replace(/\s/g, '_');
            return base || 'poster';
          }

          function fetchBuffer(url, timeoutMs = 12000, maxRedirects = 4) {
            return new Promise((resolve, reject) => {
              const visited = new Set();
              function doRequest(target, redirectsLeft) {
                try {
                  if (visited.has(target)) return reject(new Error('redirect loop'));
                  visited.add(target);
                  const lib = target.startsWith('https:') ? https : http;
                  const req = lib.get(target, {
                    headers: {
                      'User-Agent': 'Mozilla/5.0 (GitHubActions; +https://github.com) RSP-AnimeSourceMaintainer',
                      'Accept': 'image/*,*/*;q=0.8',
                      'Connection': 'close'
                    }
                  }, res => {
                    const status = res.statusCode || 0;
                    if ([301,302,303,307,308].includes(status) && res.headers.location && redirectsLeft > 0) {
                      const next = new URL(res.headers.location, target).href;
                      res.resume();
                      return doRequest(next, redirectsLeft - 1);
                    }
                    if (status !== 200) {
                      res.resume();
                      return reject(new Error('HTTP ' + status));
                    }
                    const chunks = [];
                    res.on('data', d => chunks.push(d));
                    res.on('end', () => {
                      const buf = Buffer.concat(chunks);
                      resolve({ buf, contentType: res.headers['content-type'] || '' });
                    });
                  });
                  req.on('error', reject);
                  req.setTimeout(timeoutMs, () => req.destroy(new Error('timeout')));
                } catch (e) { reject(e); }
              }
              if (url && url.startsWith('//')) url = 'https:' + url;
              doRequest(url, maxRedirects);
            });
          }

          (async () => {
            // Load existing index
            let existingData = { sources: [] };
            if (fs.existsSync(INDEX_FILE)) {
              try {
                const existing = fs.readFileSync(INDEX_FILE, 'utf8');
                existingData = JSON.parse(existing);
                if (!Array.isArray(existingData.sources)) existingData.sources = [];
              } catch (e) {
                console.warn('Could not parse existing index, starting fresh:', e.message);
              }
            }

            // Get changed files from git
            const changedFiles = new Set();
            try {
              const { execSync } = require('child_process');
              const gitDiff = execSync('git diff --name-only HEAD~1 HEAD 2>/dev/null || echo ""', { encoding: 'utf8' });
              gitDiff.split('\n')
                .filter(line => line.startsWith(FILE_DIR) && line.toLowerCase().endsWith('.json'))
                .forEach(line => changedFiles.add(path.basename(line)));
            } catch (e) {
              console.warn('Could not determine changed files, will process all:', e.message);
            }

            const files = fs.readdirSync(FILE_DIR)
              .filter(f => f.toLowerCase().endsWith('.json') && f.toLowerCase() !== 'exampledir.json');

            // Build map of existing sources
            const existingMap = new Map();
            for (const src of existingData.sources) {
              if (src.file) existingMap.set(src.file, src);
            }

            // Process only changed files (or all if we can't determine changes)
            const filesToProcess = changedFiles.size > 0 
              ? files.filter(f => changedFiles.has(f))
              : files;

            console.log(`Processing ${filesToProcess.length} file(s) out of ${files.length} total`);

            for (const file of filesToProcess) {
              try {
                const full = path.join(FILE_DIR, file);
                const raw = fs.readFileSync(full, 'utf8');
                const json = JSON.parse(raw);
                if (isMaintainerHidden(json)) {
                  console.log('Skipping hidden directory:', file);
                  existingMap.delete(file); // Remove if was previously indexed
                  continue;
                }

                const title = json.title || path.parse(file).name;
                const cats = Array.isArray(json.categories) ? json.categories : [];
                let categoryCount = 0;
                let episodeCount = 0;
                let separatedCategoryCount = 0;
                let separatedItemCount = 0;
                let totalFileSizeBytes = 0;
                let totalDurationSeconds = 0;
                for (const c of cats) {
                  const entries = getCategoryEntries(c);
                  const isSeparated = coerceSeparatedFlag(c && (c.separated ?? c.seperated));
                  if (isSeparated) {
                    separatedCategoryCount += 1;
                    separatedItemCount += entries.length;
                  } else {
                    categoryCount += 1;
                    episodeCount += entries.length;
                  }
                  for (const entry of entries) {
                    const stats = deriveEpisodeStats(entry);
                    if (stats.size > 0) totalFileSizeBytes += stats.size;
                    if (stats.duration > 0) totalDurationSeconds += stats.duration;
                  }
                }
                if ((totalFileSizeBytes <= 0 || !Number.isFinite(totalFileSizeBytes)) && Number.isFinite(Number(json.totalFileSizeBytes))) {
                  totalFileSizeBytes = Number(json.totalFileSizeBytes);
                }
                if ((totalDurationSeconds <= 0 || !Number.isFinite(totalDurationSeconds)) && Number.isFinite(Number(json.totalDurationSeconds))) {
                  totalDurationSeconds = Number(json.totalDurationSeconds);
                }
                totalFileSizeBytes = Number.isFinite(totalFileSizeBytes) && totalFileSizeBytes > 0 ? Math.round(totalFileSizeBytes) : 0;
                totalDurationSeconds = Number.isFinite(totalDurationSeconds) && totalDurationSeconds > 0 ? Math.round(totalDurationSeconds) : 0;
                const totalItemCount = episodeCount + separatedItemCount;

                // Build poster file in repo (WebP, height=512) and reference by path
                let poster = null;
                const imgUrl = (json.Image && json.Image !== 'N/A') ? json.Image : (json.image && json.image !== 'N/A' ? json.image : null);
                if (imgUrl) {
                  try {
                    const posterName = safePosterName(title, path.parse(file).name) + '.webp';
                    const posterAbs = path.join(POSTERS_DIR, posterName);
                    
                    if (fs.existsSync(posterAbs)) {
                      console.log('Poster already exists, skipping:', posterAbs);
                      poster = `./Posters/Anime/${posterName}`;
                    } else {
                      let sourceBuffer;
                      if (imgUrl.startsWith('data:')) {
                        const m = imgUrl.match(/^data:.*?;base64,(.*)$/);
                        if (!m) throw new Error('Unsupported data URI format');
                        sourceBuffer = Buffer.from(m[1], 'base64');
                      } else {
                        const { buf } = await fetchBuffer(imgUrl);
                        sourceBuffer = buf;
                      }
                      const webpBuf = await sharp(sourceBuffer)
                        .resize({ height: 512 })
                        .webp({ quality: 80 })
                        .toBuffer();

                      fs.writeFileSync(posterAbs, webpBuf);
                      console.log('Wrote poster:', posterAbs);
                      poster = `./Posters/Anime/${posterName}`;
                    }
                  } catch (e) {
                    console.warn('Poster build failed for', file, '-', e.message);
                  }
                }

                // Update or add the source entry
                existingMap.set(file, {
                  file,
                  path: `./Files/Anime/${file}`,
                  title,
                  poster,
                  categoryCount,
                  episodeCount,
                  ...(totalItemCount > 0 ? { itemCount: totalItemCount } : {}),
                  ...(separatedCategoryCount > 0 ? {
                    separatedCategoryCount,
                    separatedItemCount
                  } : {}),
                  totalFileSizeBytes,
                  ...(totalDurationSeconds > 0 ? { totalDurationSeconds } : {}),
                  LatestTime: json.LatestTime || null
                });
              } catch (e) {
                console.warn('Skipping', file, e.message);
              }
            }

            // Remove entries for files that no longer exist
            for (const file of existingMap.keys()) {
              if (!files.includes(file)) {
                console.log('Removing deleted file from index:', file);
                existingMap.delete(file);
              }
            }

            // Build final sorted array
            const result = { sources: Array.from(existingMap.values()) };
            result.sources.sort((a, b) => String(a.title).localeCompare(String(b.title)));

            fs.writeFileSync(INDEX_FILE, JSON.stringify(result, null, 2));
          })().catch(err => { console.error(err); process.exit(1); });
          NODE
          }

          attempts=0
          max_attempts=3
          while [ "$attempts" -lt "$max_attempts" ]; do
            attempts=$((attempts + 1))
            echo "Attempt ${attempts}/${max_attempts}: syncing repository and regenerating assets."

            git fetch --no-tags --prune origin "$BRANCH"
            git checkout "$BRANCH"
            git reset --hard "origin/$BRANCH"

            if [ -d "$POSTERS_DIR" ]; then
              git clean -fd -- "$POSTERS_DIR"
            fi

            base_commit=$(git rev-parse HEAD)

            generate_sources

            status_paths=("$INDEX_FILE")
            if [ -d "$POSTERS_DIR" ]; then
              status_paths+=("$POSTERS_DIR")
            fi

            if [ -z "$(git status --porcelain -- "${status_paths[@]}")" ]; then
              echo "No changes detected for $INDEX_FILE or $POSTERS_DIR; nothing to commit."
              exit 0
            fi

            git config user.name "$COMMIT_USER_NAME"
            git config user.email "$COMMIT_USER_EMAIL"

            git add --all -- "${status_paths[@]}"

            git commit -m "$COMMIT_MESSAGE"

            git fetch --no-tags --prune origin "$BRANCH"
            remote_head=$(git rev-parse "origin/$BRANCH")

            if [ "$remote_head" != "$base_commit" ]; then
              echo "origin/$BRANCH advanced from $base_commit to $remote_head before push; retrying."
              continue
            fi

            if git push --force-with-lease=refs/heads/$BRANCH:$base_commit origin HEAD:"$BRANCH"; then
              echo "Updates pushed successfully."
              exit 0
            fi

            echo "Push failed; retrying..."
          done

          echo "Failed to push updates after $max_attempts attempts." >&2
          exit 1
